import copy
import sys
from datetime import datetime

import numpy

from algorithms.Perceptron import MultiPerceptron
from utils.Config_p import Config
from utils.Graph import graph, graph_multi
from utils.PerceptronParameters import PerceptronParameters


def __main__():
    print('Argument List:', str(sys.argv))
    assert len(sys.argv) == 4, 'Missing arguments'
    f = open(sys.argv[1])
    config: Config = Config(f.read())
    f.close()

    x = []
    with open(sys.argv[2], 'r') as inputs_file:
        for line in inputs_file:
            values = line.split()
            aux = []
            for v in values:
                aux.append(float(v))
            aux.append(float(1))
            x.append(aux)
    x = numpy.array(x)

    k = config.k
    if len(x) % k != 0:
        print("length of training set is not divisible by k-fold parameter.")
        return 0

    y: [] = []
    with open(sys.argv[3], 'r') as expected_outputs_file:
        for line in expected_outputs_file:
            values = line.split()
            aux = []
            for v in values:
                aux.append(float(v))
            y.append(numpy.array(aux))

    y = numpy.array(y)

    perceptron_parameters: PerceptronParameters = PerceptronParameters(config)

    perceptron: MultiPerceptron = MultiPerceptron(perceptron_parameters, len(x[0]), len(y[0]))

    # Seleccionar cu치l es el mejor betha para entrenar a la red
    bethas = [0.1, 0.2, 0.5, 0.8, 1, 1.2, 1.5, 2]
    aux_parameters = copy.deepcopy(perceptron_parameters)
    errors_logistic = []
    errors_tanh = []

    for i in range(len(bethas)):
        train_aux(perceptron, x, y, bethas[i], 'tanh', errors_tanh, aux_parameters)
        train_aux(perceptron, x, y, bethas[i], 'logistic', errors_logistic, aux_parameters)

    graph(bethas, errors_logistic, 'Betha', 'Error', 'Errores para distintos bethas (logistic)')
    graph(bethas, errors_tanh, 'Betha', 'Error', 'Errores para distintos bethas (tanh)')

    print('Running ' + config.perceptron_algorithm + '...')
    perceptron.__init__(perceptron_parameters, len(x[0]), len(y[0]))
    results = perceptron.train(x, y)
    print(config.perceptron_algorithm + ' finished.')
    output_dir = './errors_' + config.perceptron_algorithm + '_' + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + '.png'
    graph(range(results.iterations), results.errors, 'x', 'y', 'Errores por Iteraci칩n', output_dir=output_dir)

    # Cu치l es la mejor cantidad de capas y unidades
    layers = [[2], [2, 2], [3, 3], [6, 6], [3, 2, 3]]
    aux_parameters = copy.deepcopy(perceptron_parameters)

    x_graph = []
    y_graph = []
    labels = []
    for i in range(len(layers)):
        aux_parameters.layers = layers[i]
        perceptron.__init__(aux_parameters, len(x[0]), len(y[0]))
        results = perceptron.train(x, y)
        x_graph.append(range(results.iterations))
        y_graph.append(results.errors)
        labels.append(str(layers[i]))

    graph_multi(x_graph, y_graph, 'x', 'y', 'Errores por Iteraci칩n usando distinta cantidad de capas', labels)


def train_aux(perceptron, x, y, betha, function, errors, parameters):
    parameters.betha = betha
    parameters.function = function
    perceptron.__init__(parameters, len(x[0]), len(y[0]))
    r_train = perceptron.train(x, y)
    errors.append(r_train.errors[-1])


if __name__ == "__main__":
    __main__()
